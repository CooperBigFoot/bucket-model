{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Jupyter Notebooks\n",
    "\n",
    "Welcome to the Jupyter Hub! Jupyter Notebooks provide an interactive environment where you can mix text, equations, programming code, and visual outputs. Here’s a quick guide on how to use it:\n",
    "\n",
    "### Cells\n",
    "\n",
    "A notebook is made up of cells. Each cell can contain text or code. There are two main types of cells:\n",
    "\n",
    "- **Markdown cells**: These contain formatted text written in Markdown and can include images, links, and embedded HTML. This cell is a Markdown cell. You can double-click on it to see the source code. After editing, you can run the cell to render the text.\n",
    "- **Code cells**: These contain code to be executed by the kernel (the notebook's computational engine). In this notebook, you'll be using Python code cells.\n",
    "\n",
    "### Running Cells\n",
    "\n",
    "To run a cell:\n",
    "\n",
    "1. Click on the cell to select it.\n",
    "2. Press `Shift + Enter` to execute the cell content. Alternatively, you can use the \"Run\" button in the toolbar.\n",
    "\n",
    "Sometimes you'll need to restart. To do this, click on the \"Kernel\" menu and select \"Restart Kernel and Clear All Outputs\".\n",
    "\n",
    "### Editing Cells\n",
    "\n",
    "To edit any cell, double-click on it. If it’s a code cell, you can start typing your code directly. For markdown cells, after double-clicking, you'll see the Markdown text. You can make changes and run the cell to see the updated format.\n",
    "\n",
    "### Saving Your Work\n",
    "\n",
    "You can save your work by clicking on the floppy disk icon in the toolbar or by pressing `Ctrl + S` on your keyboard. For mac users, press `Cmd + S`.\n",
    "\n",
    "### Adding and Deleting Cells\n",
    "\n",
    "You can add new cells by clicking the \"+\" icon on the toolbar. To delete a cell, select it and click the scissors icon, or press `D` twice on your keyboard when in command mode (press `Esc` to enter command mode).\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "For help with any Python function, type the function name followed by a question mark `?` and run the cell (e.g., `print?`).\n",
    "\n",
    "### That's it!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial\n",
    "\n",
    "In this tutorial I will show you how to use the code for the Bucket Model. Sometimes you will see `FutureWarning` messages. You can ignore these messages.\n",
    "\n",
    "### Importing Libraries\n",
    "\n",
    "First you need to import the code for the Bucket Model. You can do this by running the cell below. Click `Shift + Enter` to run the cell. The green tick mark indicates that the cell has been run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bucket_model import BucketModel  # This where the Bucket Model is defined\n",
    "from bucket_model_optimizer import (\n",
    "    BucketModelOptimizer,\n",
    ")  # This class allows you to calibrate the model parameters and evaluate the model performance\n",
    "from data_processing import (\n",
    "    preprocess_data,\n",
    "    train_validate_split,\n",
    ")  # This class allows you to preprocess the data and split it into training and validation sets\n",
    "\n",
    "from bucket_model_plotter import (\n",
    "    plot_water_balance,  # This script contains functions to plot the results of the model\n",
    "    plot_Q_Q,\n",
    "    plot_ECDF,\n",
    "    plot_boxplots,\n",
    "    plot_monthly_boxplot,\n",
    "    plot_timeseries,\n",
    "    plot_parameter_kde,\n",
    ")\n",
    "\n",
    "import pandas as pd  # This is a library for data manipulation.\n",
    "\n",
    "import warnings  # This is a library to handle warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # This is to ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "\n",
    "In the next cell you need to set the path to the data file, the path to the output file and the catchment area. You can do this by editing the cell below and running it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATCHMENT = \"LATTERBACH_METEO_NEW\"\n",
    "\n",
    "path_to_file = \"data/LATTERBACH_METEO_FULL.txt\"\n",
    "catchment_area = 561.7  # km^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 1: Develop a daily water balance model\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "In the next cell you will pre-process the data. This will store the data into a pandas dataframe. A pandas dataframe is like an Excel spreadsheet; it is a 2-dimensional table where you can organize, manipulate, and analyze data easily. You need to provide the catchment area for the transformation of the units from m^3/s to mm/day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(\n",
    "    path_to_file=path_to_file, catchment_area=catchment_area, filter_dates=(1986, 1999)\n",
    ")  # This is to preprocess the data\n",
    "\n",
    "# Let's have a look at the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model and set the catchment properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BucketModel with initial parameter guesses\n",
    "bucket = BucketModel(\n",
    "    k=0.5,  # degree-day snowmelt parameter\n",
    "    S_max=35,  # max soil water storage\n",
    "    fr=0.8,  # fraction of impermeable area at soil saturation\n",
    "    rg=7,  # mean residence time of water in groundwater\n",
    "    snow_threshold_temp=0,\n",
    ")  # threshold temperature for snowfall\n",
    "\n",
    "# Set the catchment properties\n",
    "bucket.set_catchment_properties(\n",
    "    lapse_rate=0.5 / 100,  # °C/m\n",
    "    basin_mean_elevation=2035,  # m.a.s.l 1638\n",
    "    hru_mean_elevation=2035,  # m.a.s.l\n",
    "    snowmelt_temp_threshold=0,  # °C\n",
    "    latitude=46.9,  # °N\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also change the initial conditions of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.change_initial_conditions(S=10, S_gw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run_results = bucket.run(data=data)\n",
    "\n",
    "# Let's have a look at them\n",
    "first_run_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "To save the plots just add the `output_destination` parameter to the `plot` function. For example:\n",
    "\n",
    "```python\n",
    "output_destination = 'images/first_wat_bal.png'\n",
    "plot_water_balance(results=first_run_results, output_destination=output_destination)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_water_balance(results=first_run_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(\n",
    "    results=first_run_results,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\", \"black\"],\n",
    "    plot_precipitation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at some stats:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly_boxplot(results=first_run_results, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment the following lines to see all other plots:\n",
    "\n",
    "The plots have some more customization options. You can have a look at the `bucket_model_plotter.py` file to see all the options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q_Q(results=first_run_results, observed=data)\n",
    "\n",
    "plot_ECDF(results=first_run_results, observed=data, palette=[\"red\", \"blue\"])\n",
    "\n",
    "plot_boxplots(results=first_run_results, observed=data, palette=[\"red\", \"blue\"])\n",
    "\n",
    "plot_timeseries(\n",
    "    results=first_run_results,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\"],\n",
    "    monthly=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the parameters\n",
    "\n",
    "The first guess is not very impressive. Let's try another guess and see how it goes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_guess = {\n",
    "    \"k\": 0.6,\n",
    "    \"S_max\": 40,\n",
    "    \"fr\": 0.2,\n",
    "    \"rg\": 14.5,\n",
    "    \"snow_threshold_temp\": 2.0,\n",
    "}\n",
    "\n",
    "bucket.update_parameters(parameters=second_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check that the parameters have been updated by printing the model:\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_run_results = bucket.run(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(\n",
    "    results=second_run_results,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\"],\n",
    "    monthly=True,\n",
    ")\n",
    "plot_Q_Q(results=second_run_results, observed=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Finding a Good Fit\n",
    "\n",
    "Iteratively change the model parameters until you find a visually good fit. Invest some time to understand how each parameter influences the results. Here is a step-by-step guide to help you with this process:\n",
    "\n",
    "1. **Define Your New Guess**\n",
    "\n",
    "   You can define your new guess just like we did for the second guess:\n",
    "\n",
    "   ```python\n",
    "   new_guess = {\n",
    "      'k': 0.2,\n",
    "      'S_max': 35,\n",
    "      'fr': 0.2,\n",
    "      'rg': 17,\n",
    "      'snow_threshold_temp': 1\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Update model parameters**\n",
    "\n",
    "   Update the model parameters with your new guess:\n",
    "\n",
    "   ```python\n",
    "   model.update_parameters(new_guess)\n",
    "   ```\n",
    "\n",
    "3. **Run the model**\n",
    "\n",
    "   Run the model with the new parameters:\n",
    "\n",
    "   ```python\n",
    "   model.run()\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2: Automatic calibration/validation of the daily water balance model\n",
    "\n",
    "### Split the data into a training (calibration) and validation set\n",
    "\n",
    "The `train_size` parameter defines the size of the training set. In the example below we use 80% of the data for training and 20% for validation. Feel free to change that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validate_data = train_validate_split(data=data, train_size=0.666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the training data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the validation data\n",
    "validate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Calibration of Model Parameters\n",
    "\n",
    "To automatically calibrate the model parameters, follow these steps:\n",
    "\n",
    "1. **Initialize a BucketModelOptimizer**\n",
    "\n",
    "   This is the first step in the calibration process.\n",
    "\n",
    "2. **Define the Method**\n",
    "\n",
    "   You need to define the method that will be used for the calibration: `local` or `n-folds`.\n",
    "\n",
    "3. **Set the Parameter Bounds**\n",
    "\n",
    "   Define the bounds for the parameters. This will guide the calibration process.\n",
    "\n",
    "After setting up, you can start the calibration process. When you call the `calibrate` method, a uniform random guess is sampled from the parameter bounds and the optimization begins. Let's start simple with the local optimization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BucketModelOptimizer with the BucketModel instance and observed data\n",
    "optimizer = BucketModelOptimizer(\n",
    "    model=bucket, training_data=train_data, validation_data=validate_data\n",
    ")\n",
    "# Define the method\n",
    "method = \"local\"\n",
    "\n",
    "# Define the parameter bounds\n",
    "bounds = {\n",
    "    \"k\": (1, 1.5),\n",
    "    \"S_max\": (10, 50),\n",
    "    \"fr\": (0.1, 0.3),\n",
    "    \"rg\": (10, 35),\n",
    "    \"snow_threshold_temp\": (-1.0, 4.0),\n",
    "}\n",
    "\n",
    "# Now set the options\n",
    "optimizer.set_options(method=method, bounds=bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now calibrate, it can take up to a minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_parameters, _ = optimizer.calibrate(\n",
    "    verbose=True, initial_guess=[1.0, 30.79, 0.1, 23.23, 1.88]\n",
    ")  # For now don't worry about the second output (_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the calibrated parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"calibrated_parameters:\", calibrated_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the model performance\n",
    "\n",
    "We will score the model by looking at the Nash-Sutcliffe Efficiency (NSE), the Root Mean Squared Error (RMSE) and the Kling-Gupta Efficiency (KGE). In the `metrics.py` file you can find the formulas for these and other metrics.\n",
    "\n",
    "The `score_model` function will score the model on the training and validation data separately. Does that make sense to you?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perfomance = optimizer.score_model(metrics=[\"NSE\", \"RMSE\", \"KGE\"])\n",
    "\n",
    "# Let's have a look at the model performance\n",
    "print(\"model performance:\", model_perfomance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the model with the calibrated parameters. The optimizer works with a copy of the model, so you need to synchronize the model with the calibrated parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_calibrated = (\n",
    "    optimizer.get_optimized_model()\n",
    ")  # Now your bucket model has the calibrated parameters :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_results = bucket_calibrated.run(data=data)\n",
    "plot_timeseries(\n",
    "    results=calibrated_results,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\", \"black\"],\n",
    "    plot_precipitation=True,\n",
    "    output_destination=\"images/timeseries_with_precip.png\",\n",
    ")\n",
    "plot_Q_Q(results=calibrated_results, observed=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Fold Calibration\n",
    "\n",
    "In the N-Fold calibration approach, the model is more robustly calibrated by N sampling initial guesses from the parameter bounds. For each sample, the BucketModelOptimizer finds a local minimum, improving the chances of reaching the 'best possible fit' by exploring different starting points. These parameter sets are stored in a DataFrame.\n",
    "\n",
    "After performing the N-Fold calibration, the best set of parameters is identified using the `get_best_parameters` method. This method evaluates each parameter set based on the RMSE. You can change the metric in the `bucket_model_optimizer.py` file.\n",
    "\n",
    "Let's try it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BucketModelOptimizer with the BucketModel instance and observed data\n",
    "optimizer = BucketModelOptimizer(\n",
    "    model=bucket, training_data=train_data, validation_data=validate_data\n",
    ")\n",
    "# Define the method\n",
    "method = \"n-folds\"\n",
    "\n",
    "# Define the parameter bounds\n",
    "bounds = {\n",
    "    \"k\": (1, 3),\n",
    "    \"S_max\": (10, 50),\n",
    "    \"fr\": (0.0, 0.3),\n",
    "    \"rg\": (5, 35),\n",
    "    \"snow_threshold_temp\": (-1.0, 4.0),\n",
    "}\n",
    "\n",
    "# Now set the options\n",
    "optimizer.set_options(\n",
    "    method=method, bounds=bounds, folds=5\n",
    ")  # Now you need to define the number of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration is going to take a while (circa 10 minutes). Be patient :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_parameters, n_folds_results = optimizer.calibrate()\n",
    "\n",
    "# Let's have a look at the n-folds results\n",
    "n_folds_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the parameter distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_kde(n_fold_results=n_folds_results, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_kde(n_fold_results=n_folds_results, bounds=bounds, plot_type=\"kdeplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"images_new_data\"\n",
    "\n",
    "# Let's sync the models\n",
    "n_fold_calibrated_model = optimizer.get_optimized_model()\n",
    "\n",
    "final_run = n_fold_calibrated_model.run(data=data)\n",
    "\n",
    "plot_timeseries(\n",
    "    results=final_run,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\"],\n",
    "    monthly=True,\n",
    ")\n",
    "plot_timeseries(\n",
    "    results=final_run,\n",
    "    observed=data,\n",
    "    start_year=\"1986\",\n",
    "    end_year=\"2000\",\n",
    "    palette=[\"red\", \"blue\"],\n",
    ")\n",
    "plot_water_balance(results=final_run)\n",
    "plot_Q_Q(results=final_run, observed=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the best parameters:\n",
    "print(n_fold_calibrated_model)\n",
    "print(calibrated_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model_perfromance = optimizer.score_model(metrics=[\"NSE\", \"RMSE\", \"KGE\"])\n",
    "calibrated_model_perfromance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK 3: Local parameter sensitivity\n",
    "\n",
    "To be discussed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.plot_of_surface(\n",
    "    param1=\"fr\", param2=\"rg\", n_points=10, unit_1=\"\", unit_2=\"days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.plot_of_surface(\n",
    "    param1=\"k\",\n",
    "    param2=\"snow_threshold_temp\",\n",
    "    n_points=10,\n",
    "    unit_1=\"mm/°C/day\",\n",
    "    unit_2=\"°C\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.local_sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.get_optimized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BucketModel(\n",
    "    k=1.505,\n",
    "    S_max=23.155,\n",
    "    fr=0.075,\n",
    "    rg=32.256,\n",
    "    snow_threshold_temp=-0.203\n",
    ")\n",
    "\n",
    "model1.set_catchment_properties(\n",
    "    lapse_rate=0.5 / 100,  # °C/m\n",
    "    basin_mean_elevation=1638,  # m.a.s.l 1638\n",
    "    hru_mean_elevation=1638,  # m.a.s.l\n",
    "    snowmelt_temp_threshold=0,  # °C\n",
    "    latitude=46.9,  # °N\n",
    ")\n",
    "\n",
    "model1.change_initial_conditions(S=10, S_gw=100)\n",
    "\n",
    "optimizer = BucketModelOptimizer(model=model1, training_data=train_data, validation_data=validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.local_sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {\n",
    "    \"k\": (1, 1.5),\n",
    "    \"S_max\": (10, 50),\n",
    "    \"fr\": (0.0, 0.3),\n",
    "    \"rg\": (5, 35),\n",
    "    \"snow_threshold_temp\": (-1.0, 4.0),\n",
    "}\n",
    "\n",
    "optimizer.bounds = bounds\n",
    "\n",
    "optimizer.plot_of_surface(\n",
    "    param1=\"fr\", param2=\"rg\", n_points=10, unit_1=\"\", unit_2=\"days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BucketModel(\n",
    "    k=1.402,\n",
    "    S_max=24.575,\n",
    "    fr=0.076,\n",
    "    rg=32.148,\n",
    "    snow_threshold_temp=-0.287\n",
    ")\n",
    "\n",
    "model1.set_catchment_properties(\n",
    "    lapse_rate=0.5 / 100,  # °C/m\n",
    "    basin_mean_elevation=1638,  # m.a.s.l 1638\n",
    "    hru_mean_elevation=1638,  # m.a.s.l\n",
    "    snowmelt_temp_threshold=0,  # °C\n",
    "    latitude=46.9,  # °N\n",
    ")\n",
    "\n",
    "model1.change_initial_conditions(S=10, S_gw=100)\n",
    "\n",
    "optimizer = BucketModelOptimizer(model=model1, training_data=train_data, validation_data=validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.local_sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BuckModEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
